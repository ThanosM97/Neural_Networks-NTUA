# Neural Networks - NTUA ECE
This repository hosts the programming exercises for the course Neural Networks of NTUA.

## Contributors:
- [Antoniadis Panagiotis](https://github.com/PanosAntoniadis)
- [Bazotis Nikolaos](https://github.com/Nick-Buzz)
- [Masouris Athanasios](https://github.com/ThanosM97)

## Lab 1 - Supervised Learning
The goal of this lab was to evaluate the performance of different supervised machine learning algorithms on two datasets taken by [UCI Machine Learning repository](https://archive.ics.uci.edu/ml/index.php) after data pre-processing and hyperparameter tuning.  

## Lab 2 - Unsupervised Learning
The goal of this lab was to develop a movie recommender system with content-based filtering, focusing on the corpuses of the movies. Then we use [Somoclu's](http://somoclu.readthedocs.io/en/stable/index.html) library to create Self Organizing Maps (SOM) and cluster our movies based on their genres. For this lab we use a subset of the [Carnegie Mellon Movie Summary Corpus](http://www.cs.cmu.edu/~ark/personas/) dataset.

## Lab 3 - Deep Learning
The goal of this lab was to familiarize ourselves with the deep neural networks architectures. The task was Image Classification on a subset of the [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. We also used Transfer Learning on some well known [architectures](https://keras.io/applications/) and on the state-of-the-art [EfficientNets](https://arxiv.org/abs/1905.11946). Moreover, apart from Transfer Learning we had to build some models "from scratch" for the same task. The first part was to build the architecture for some models and tried the best models of them on the problem . The second part was the optimization part when we applied some techniques that target to help with some difficulties that our model may face such as Overfitting , Training Time and Memory Usage.
