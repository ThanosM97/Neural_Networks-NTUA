{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSVT-Voice-Rehabilitation .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2a43f4xetzl",
        "colab_type": "text"
      },
      "source": [
        "# Team info\n",
        "- Members:\n",
        "  - Antoniadis Panagiotis - 03115009\n",
        "  - Masouris Athanasios - 03115189\n",
        "  - Bazotis Nikolaos - 03115739"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3gmSIfF-KDM",
        "colab_type": "text"
      },
      "source": [
        "# Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS7FsWyH3fSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "import pandas as pd\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rcParams['figure.figsize'] = 10 , 15\n",
        "plt.rcParams['text.color'] = \"black\"\n",
        "plt.rcParams['xtick.color'] = \"black\"\n",
        "plt.rcParams['ytick.color'] = \"black\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_nJslgVdXua",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGekWHVR4hds",
        "colab_type": "text"
      },
      "source": [
        "![UCI ML Logo](http://archive.ics.uci.edu/ml/assets/logo.gif \"UCI Machine Learning Repository\")\n",
        "\n",
        "For this project we use the [LSVT Voice Rehabilitation Data Set](https://archive.ics.uci.edu/ml/datasets/LSVT+Voice+Rehabilitation)  from the UCI Machine Learning Repository. It contains data produced via signal processing of the participants voice in order to assess whether voice rehabilitation treatment lead to phonations considered 'acceptable' or 'unacceptable'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhrwEd2u726x",
        "colab_type": "text"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O0yxlBDj_og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Uploading the data file\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tO22agcmt0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating pandas dataframe by reading the data file\n",
        "xls = pd.ExcelFile('LSVT_voice_rehabilitation.xlsx')\n",
        "df1 = pd.read_excel(xls, 'Data')\n",
        "df2 = pd.read_excel(xls, 'Binary response')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lAy7QUy7yeG",
        "colab_type": "text"
      },
      "source": [
        "## Description of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wycKIwMKr5IP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m,n = df1.shape\n",
        "print(\"Number of examples: %d\" %m)\n",
        "print(\"Number of features: %d\" %n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVPAy_LJGYMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats = df1.columns\n",
        "print(\"The features of the dataset are:\")\n",
        "print(list(feats))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I04D2czH8F8g",
        "colab_type": "text"
      },
      "source": [
        "This dataset has 126 examples and each of them has 310 features. Each of these features (attributes) corresponds to the application of a speech signal processing algorithm which aims to characterise objectively the signal. These algorithms include standard perturbation analysis methods, wavelet-based features, fundamental frequency-based features, and tools used to mine nonlinear time-series. Because of the extensive number of attributes we refer the interested readers to the relevant papers for further details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4GL6pL08eyI",
        "colab_type": "text"
      },
      "source": [
        "## Checking for non numeric features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdo8TtMOsPK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def isnumeric(df):\n",
        "  #The select below returns a dataframe with the non numeric values of df1\n",
        "  select = df1.select_dtypes(exclude=np.number)\n",
        "  #If the shape returns 0, it means there aren't any columns with non numeric values. So flag must be True, thus the negation.\n",
        "  flag = not bool(df1.select_dtypes(exclude=np.number).shape[1]) \n",
        "  #Returns a list with the column names that have non numeric values\n",
        "  not_numerics = df1.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "  return flag , not_numerics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6EUm3DTvNAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric , not_numerics = isnumeric(df1)\n",
        "if (numeric):\n",
        "  print(\"All features have numeric values\")\n",
        "else:\n",
        "  for key in not_numerics:\n",
        "    print(key + \"feature is not numeric\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b6CULKZ8rKo",
        "colab_type": "text"
      },
      "source": [
        "## Checking for missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdqNeHCM1TVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def missing_val(df):\n",
        "  #Cheking for every example if there is a column with a missing value\n",
        "  df_nulls = df.isnull().any(axis=1)\n",
        "  #Checking if there is an example with a missing value\n",
        "  flag = df_nulls.any()\n",
        "  #Returns an array of indexes for the examples with a missing value\n",
        "  null_examples = np.where(df_nulls == True)[0]\n",
        "\n",
        "  return flag , null_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVLEiNbu1k87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing , examples =  missing_val(df1)\n",
        "if missing:\n",
        "  print(\"There are %d examples with missing values,\" %examples.size)\n",
        "  print(\"so %f percent of total examples has missing values.\" %(examples.size/m *100))\n",
        "  print(\"The examples that have missing values are the following:\")\n",
        "  print(examples)\n",
        "else:\n",
        "  print(\"There are no missing values\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S6O-dy9806k",
        "colab_type": "text"
      },
      "source": [
        "## Dataset labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-2qh8843Twt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Number of labels\n",
        "print(\"The are %d labels\" %df2.nunique())\n",
        "print(df2.columns.values[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdMHPZ6Z9Z5K",
        "colab_type": "text"
      },
      "source": [
        "## Checking for biased data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf5cjHTWeOi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_acc = (df2['Binary class 1=acceptable, 2=unacceptable']==1).sum()\n",
        "n_unacc = (df2['Binary class 1=acceptable, 2=unacceptable']==2).sum()\n",
        "\n",
        "y = [n_acc, n_unacc]\n",
        "x = ['Acceptable', 'Unacceptable']\n",
        "\n",
        "\n",
        "bars = plt.bar(x,y, width=0.5)\n",
        "bars[0].set_color('g')\n",
        "bars[1].set_color('r')\n",
        "plt.title(\"Features Distribution\")\n",
        "plt.ylabel(\"Number of examples\" , color='w')\n",
        "plt.xlabel(\"Labels\", color='w')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"There are %d acceptable examples and %d unacceptable exmaples,\" %(n_acc, n_unacc))\n",
        "print(\"so %f percent of the examples are acceptable and %f percent are unacceptable.\" %(n_acc/m*100, n_unacc/m*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voL7_AMT-15S",
        "colab_type": "text"
      },
      "source": [
        "Based on the above information and the general fact that a binary dataset is imbalanced if there is a 60%-40% (or worse) difference in labeled examples, we can conclude that the classes in the dataset are imbalanced. So the dataset is biased in favor of the unacceptable examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g0gnm_oqHnN",
        "colab_type": "text"
      },
      "source": [
        "## Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsjaJGrlqYXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split our data (20% of the dataset will be the test set)\n",
        "train, test, train_labels, test_labels = train_test_split(df1, df2, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CI_D09gzwfTx"
      },
      "source": [
        "## Project questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "shrAIJX3wfHz"
      },
      "source": [
        "1. **Write a short dataset description** \\\n",
        "See [Dataset Presentation](#scrollTo=j_nJslgVdXua)\n",
        "2. **Find the number of examples and features. Search if there are non numeric features and which are those.** \\\n",
        "See [Description of features](#scrollTo=3lAy7QUy7yeG) and [Checking for non numeric features](#scrollTo=E4GL6pL08eyI).\n",
        "3. **Check if there are any headers and line numbering.** \\\n",
        "The first row of the data file (LSVT_voice_rehabilitation.xlsx) contains the names of corresponding features. We read the first line as headers in the pandas dataframe and we can find them [here](#scrollTo=SVPAy_LJGYMs). There is not a line numbering.\n",
        "4. **Which are the labels for the corresponding classes?** \\\n",
        "The labels for the classes where on a different DataSheet on the same data file (LSVT_voice_rehabilitation.xlsx) and as we can see [here](#scrollTo=6S6O-dy9806k) they are 'Acceptable' and 'Unacceptable'.\n",
        "5. **Did you have to modify the .txt files?** \\\n",
        "There is not a .txt file containing data in this dataset. The .txt file provided at the repository contains a description of the dataset.\n",
        "6. **Are there any missing values in the dataset? On which examples? What is the percentage of the examples with a missing value?** \\\n",
        "As we can see at [Checking for missing values](#scrollTo=9b6CULKZ8rKo) there are no missing values in the dataset for all of the examples.\n",
        "7. **Find how many classes there are and check the balance of the dataset by calculating the percentage of examples each class has.** \\\n",
        "As we can see [here](#scrollTo=6S6O-dy9806k) there are two classes. 1 for acceptable examples and 2 for unacceptable. Then at [Checking for biased data](#scrollTo=vdMHPZ6Z9Z5K) we can see that the dataset is imbalanced because 33.33% of the examples are acceptable and 66.66% unacceptable. Which means that the dataset is biased in favor of the unacceptable examples.\n",
        "8. **Split the dataset to train/test sets and explain how you chose to handle the missing values and the non numeric values.** \\\n",
        "In the section [Train/Test split](#scrollTo=_g0gnm_oqHnN) we use the function sklearn.model_selection.train_test_split in order to split randomly our dataset to train and test subsets. We use the parameter test_size=0.20 in order to declare that we want the test set to be 20% of the whole dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr3eNahpIKqH",
        "colab_type": "text"
      },
      "source": [
        "# Baseline classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60PC2RkuuWud",
        "colab_type": "text"
      },
      "source": [
        "For this project we are going to train and optimize some dummy classifiers and the k-nearest neighbors classifier. In this section we are going to do a baseline classification in order to see how well these classifiers do on our dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8WDVASlwLbz",
        "colab_type": "text"
      },
      "source": [
        "First, we will convert the data from pandas dataframes to numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xo5jFhSwW_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train.to_numpy()\n",
        "Y_train = train_labels.to_numpy().reshape(len(train_labels))\n",
        "X_test = test.to_numpy()\n",
        "Y_test = test_labels.to_numpy().reshape(len(test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx_cygCpuHJi",
        "colab_type": "text"
      },
      "source": [
        "## Dummy classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfqnKaVZ97zk",
        "colab_type": "text"
      },
      "source": [
        "In this section we are going to check the accuracy of the common dummy classifiers on our dataset. We are going to use the module DummyClassifier provided by sklearn. We will try the following strategies: \\\n",
        "- Uniform (random)\n",
        "- Constant (1 or 2, for our classes)\n",
        "- Most frequent\n",
        "- Stratified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlCrJ32QvpuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
        "dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n",
        "dc_constant_2 = DummyClassifier(strategy=\"constant\", constant=2)\n",
        "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dc_stratified = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "#The fit method from sklearn trains the model to the training set we provide as an argument.\n",
        "model_uniform = dc_uniform.fit(X_train, Y_train)\n",
        "model_constant_1 = dc_constant_1.fit(X_train, Y_train)\n",
        "model_constant_2 = dc_constant_2.fit(X_train, Y_train)\n",
        "model_most_frequent = dc_most_frequent.fit(X_train, Y_train)\n",
        "model_stratified = dc_stratified.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "#Using the predict method we can then make predictions on the test set\n",
        "\n",
        "#Uniform predictions\n",
        "preds_uniform = dc_uniform.predict(X_test)\n",
        "print(\"Uniform dummy classifier - predictions:\", end=\" \")\n",
        "print(preds_uniform)\n",
        "\n",
        "#Constant 1\n",
        "preds_constant_1 = dc_constant_1.predict(X_test)\n",
        "print(\"Constant 1 dummy classifier - predictions:\", end=\" \")\n",
        "print(preds_constant_1)\n",
        "\n",
        "#Constant 2\n",
        "preds_constant_2 = dc_constant_2.predict(X_test)\n",
        "print(\"Constant 2 dummy classifier - predictions:\", end=\" \")\n",
        "print(preds_constant_2)\n",
        "\n",
        "#Most frequent predictions\n",
        "preds_most_frequent= dc_most_frequent.predict(X_test)\n",
        "print(\"Most frequent dummy classifier - predictions:\", end=\" \")\n",
        "print(preds_most_frequent)\n",
        "\n",
        "#Stratified predictions\n",
        "preds_stratified= dc_stratified.predict(X_test)\n",
        "print(\"Stratified dummy classifier - predictions:\", end=\" \")\n",
        "print(preds_stratified)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMLUHsK0-njB",
        "colab_type": "text"
      },
      "source": [
        "Now based on the models we trained and the predictions they produce, we are going to calculate the accuracy of each strategy on our test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY2LAmSAwAFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a dictionary with the accuracies of the dummy strategies\n",
        "dummies_accuracy = {}\n",
        "dummies_accuracy['uniform'] = model_uniform.score(X_test, Y_test)\n",
        "dummies_accuracy['constant_1'] = model_constant_1.score(X_test, Y_test)\n",
        "dummies_accuracy['constant_2'] = model_constant_2.score(X_test, Y_test)\n",
        "dummies_accuracy['most frequent label'] = model_most_frequent.score(X_test, Y_test)\n",
        "dummies_accuracy['stratified'] = model_stratified.score(X_test, Y_test)\n",
        "\n",
        "#Creating a barplot for the accuracies\n",
        "x = [key for key in dummies_accuracy.keys()]\n",
        "y = [value for value in dummies_accuracy.values()]\n",
        "bars = plt.bar(x,y, width=0.5)\n",
        "plt.title(\"Accuracy with dummy classifiers\")\n",
        "plt.ylabel(\"Accuracy\" , color='w')\n",
        "plt.xlabel(\"Strategy\", color='w')\n",
        "plt.show()\n",
        "\n",
        "#Printing the sorted results\n",
        "print(\"Classification Accuracy on the LSVT Voice Rehabilitation Data Set (20% test set)\\n\")\n",
        "sorted_accuracy = [(k, dummies_accuracy[k]) for k in sorted(dummies_accuracy, key=dummies_accuracy.get, reverse=True)]\n",
        "for k, v in sorted_accuracy:\n",
        "  print(k,v)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec6feAmO-2N6",
        "colab_type": "text"
      },
      "source": [
        "Since the uniform strategy is random, every time we run the above cell the accuracy calculated will be different. \\\n",
        "After multiple reruns of the above cell we can observe that: \\\n",
        "\n",
        "\n",
        "1.   Constant 2 (same as most frequent) is the best strategy for this dataset\n",
        "2.   The uniform strategy (here ranks 3rd) could be the best in some runs, but generally ranks 4th. This happens because the stratified strategys' predictions respect the class distribution of the dataset and also the dataset is imbalanced.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKgxR1us_wf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "UNDERLINE = '\\033[4m'\n",
        "END = '\\033[0m'\n",
        "\n",
        "#Calculating the confusion matrices of the above strategies\n",
        "dummies_cm = {}\n",
        "dummies_cm['uniform'] = confusion_matrix(Y_test,preds_uniform)\n",
        "dummies_cm['constant_1'] = confusion_matrix(Y_test,preds_constant_1)\n",
        "dummies_cm['constant_2'] = confusion_matrix(Y_test,preds_constant_2)\n",
        "dummies_cm['most frequent label'] = confusion_matrix(Y_test,preds_most_frequent)\n",
        "dummies_cm['stratified'] = confusion_matrix(Y_test,preds_stratified)\n",
        "\n",
        "#Calculating the f1 micro average score of the above strategies\n",
        "dummies_f1_micro = {}\n",
        "dummies_f1_micro['uniform'] = f1_score(Y_test, preds_uniform, average=\"micro\")\n",
        "dummies_f1_micro['constant_1'] = f1_score(Y_test, preds_constant_1, average=\"micro\")\n",
        "dummies_f1_micro['constant_2'] = f1_score(Y_test, preds_constant_2, average=\"micro\")\n",
        "dummies_f1_micro['most frequent label'] = f1_score(Y_test, preds_most_frequent, average=\"micro\")\n",
        "dummies_f1_micro['stratified'] = f1_score(Y_test, preds_stratified, average=\"micro\")\n",
        "\n",
        "#Calculating the f1 macro average score of the above strategies\n",
        "dummies_f1_macro = {}\n",
        "dummies_f1_macro['uniform'] = f1_score(Y_test, preds_uniform, average=\"macro\")\n",
        "dummies_f1_macro['constant_1'] = f1_score(Y_test, preds_constant_1, average=\"macro\")\n",
        "dummies_f1_macro['constant_2'] = f1_score(Y_test, preds_constant_2, average=\"macro\")\n",
        "dummies_f1_macro['most frequent label'] = f1_score(Y_test, preds_most_frequent, average=\"macro\")\n",
        "dummies_f1_macro['stratified'] = f1_score(Y_test, preds_stratified, average=\"macro\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Confusion matrix for the \" + UNDERLINE + \"uniform strategy\" + END +\":\")\n",
        "print(dummies_cm['uniform'])\n",
        "print(\"f1-micro average: %f\" %dummies_f1_micro['uniform'])\n",
        "print(\"f1-macro average: %f\" %dummies_f1_macro['uniform'])\n",
        "\n",
        "print(\"\\nConfusion matrix for the \" + UNDERLINE + \"constant 1 strategy\" + END +\":\")\n",
        "print(dummies_cm['constant_1'])\n",
        "print(\"f1-micro average: %f\" %dummies_f1_micro['constant_1'])\n",
        "print(\"f1-macro average: %f\" %dummies_f1_macro['constant_1'])\n",
        "\n",
        "print(\"\\nConfusion matrix for the \" + UNDERLINE + \"constant 2 strategy\" + END +\":\")\n",
        "print(dummies_cm['constant_2'])\n",
        "print(\"f1-micro average: %f\" %dummies_f1_micro['constant_2'])\n",
        "print(\"f1-macro average: %f\" %dummies_f1_macro['constant_2'])\n",
        "\n",
        "print(\"\\nConfusion matrix for the \" + UNDERLINE + \"most frequent strategy\" + END +\":\")\n",
        "print(dummies_cm['most frequent label'])\n",
        "print(\"f1-micro average: %f\" %dummies_f1_micro['most frequent label'])\n",
        "print(\"f1-macro average: %f\" %dummies_f1_macro['most frequent label'])\n",
        "\n",
        "print(\"\\nConfusion matrix for the \" + UNDERLINE + \"stratified strategy\" + END +\":\")\n",
        "print(dummies_cm['stratified'])\n",
        "print(\"f1-micro average: %f\" %dummies_f1_micro['stratified'])\n",
        "print(\"f1-macro average: %f\" %dummies_f1_macro['stratified'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Gvy-hwaryz",
        "colab_type": "text"
      },
      "source": [
        "### Confusion matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AltriWpkGao3",
        "colab_type": "text"
      },
      "source": [
        "So based on the output above, we have the following confusion matrices:\n",
        "\n",
        "**Uniform Strategy**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           6           |            5            |\n",
        "| Actual Unacceptables(2) |           7           |            8            |\n",
        "\n",
        "**Constant 1 Strategy**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           11           |            0            |\n",
        "| Actual Unacceptables(2) |           15           |            0            |\n",
        "\n",
        "**Constant 2 Strategy**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           0           |            11            |\n",
        "| Actual Unacceptables(2) |           0           |            15            |\n",
        "\n",
        "**Most frequent Strategy**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           0           |            11            |\n",
        "| Actual Unacceptables(2) |           0           |            15            |\n",
        "\n",
        "\n",
        "**Stratified Strategy**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           4           |            7            |\n",
        "| Actual Unacceptables(2) |           5           |            10            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7VEu7WSagiu",
        "colab_type": "text"
      },
      "source": [
        "### F1 scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umzzWKajtYda",
        "colab_type": "text"
      },
      "source": [
        "The f1 micro and macro averages based on the above confusion matrices are the following:\n",
        "\n",
        "- Uniform strategy\n",
        "  - f1-micro average: 0.538462\n",
        "  - f1-macro average: 0.535714\n",
        "\n",
        "- Constant 1 strategy \n",
        "  - f1-micro average: 0.423077\n",
        "  - f1-macro average: 0.297297\n",
        "\n",
        "- Constant 2 strategy \n",
        "  - f1-micro average: 0.576923\n",
        "  - f1-macro average: 0.365854\n",
        "\n",
        "- Most frequent strategy \n",
        "  - f1-micro average: 0.576923\n",
        "  - f1-macro average: 0.365854\n",
        "\n",
        "- Stratified strategy \n",
        "  - f1-micro average: 0.538462\n",
        "  - f1-macro average: 0.512500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtghkvbxwO43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a barplot for the F1 micro averages\n",
        "x_micro = [key for key in dummies_f1_micro.keys()]\n",
        "y_micro = [value for value in dummies_f1_micro.values()]\n",
        "bars = plt.bar(x_micro,y_micro, width=0.5)\n",
        "plt.title(\"f1 micro score with dummy classifiers\")\n",
        "plt.ylabel(\"f1 micro score\" , color='w')\n",
        "plt.xlabel(\"Strategy\", color='w')\n",
        "plt.show()\n",
        "\n",
        "#Creating a barplot for the F1 micro averages\n",
        "x_macro = [key for key in dummies_f1_macro.keys()]\n",
        "y_macro = [value for value in dummies_f1_macro.values()]\n",
        "bars = plt.bar(x_macro,y_macro, width=0.5)\n",
        "plt.title(\"f1 macro score with dummy classifiers\")\n",
        "plt.ylabel(\"f1 macro score\" , color='w')\n",
        "plt.xlabel(\"Strategy\", color='w')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMEK8w7CuWUy",
        "colab_type": "text"
      },
      "source": [
        "### Classification reports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rBjSVp9ypbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"\\nClassification Precision, Recall, F1 on the LSVT Voice Rehabilitation Data Set (20% test set)\")\n",
        "\n",
        "print(\"\\n\"+UNDERLINE+\"Uniform strategy\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, preds_uniform))\n",
        "print(\"\\n\"+UNDERLINE+\"Constant 1 strategy\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, preds_constant_1))\n",
        "print(\"\\n\"+UNDERLINE+\"Constant 2 strategy\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, preds_constant_2))\n",
        "print(\"\\n\"+UNDERLINE+\"Most frequent strategy\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, preds_most_frequent))\n",
        "print(\"\\n\"+UNDERLINE+\"Stratified strategy\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, preds_stratified))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW8JbqynzMzx",
        "colab_type": "text"
      },
      "source": [
        "## kNN classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PSmERMrxkZ1N"
      },
      "source": [
        "In this section we are going to use the k Nearest Neighbors Classifier. \\\n",
        "\n",
        "The kNN algorithm is a non-parametric classification method. An object is classified to the class most common among its k nearest neighbors. \\\n",
        "\\\n",
        "The value of k is usually a small integer. \\\n",
        "\\\n",
        "For this section the value of k will be 5 (n_neighbors=5). We are going to search for the optimal value of k in a later section. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWzsZ0g8imx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the modules from sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Chosen value of k is 5\n",
        "k=5\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = k)\n",
        "knn.fit(X_train, Y_train)\n",
        "pred = knn.predict(X_test)\n",
        "print(\"The accuracy score for kNN algorithm with k=%d is: %f\" %(k,accuracy_score(Y_test, pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12kzhi5GoKoN",
        "colab_type": "text"
      },
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrkwHogAo48j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn_5_cm = confusion_matrix(Y_test,pred)\n",
        "print(knn_5_cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjwTxna-pG26",
        "colab_type": "text"
      },
      "source": [
        "**kNN algorithm (k=5)**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           3           |            8            |\n",
        "| Actual Unacceptables(2) |           5           |            10            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsGfrtBTpWo3",
        "colab_type": "text"
      },
      "source": [
        "### F1 scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGjhoKpqpzRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn_5_f1_micro = f1_score(Y_test, pred, average=\"micro\")\n",
        "knn_5_f1_macro = f1_score(Y_test, pred, average=\"macro\")\n",
        "\n",
        "print(\"f1-micro average: %f\" %knn_5_f1_micro)\n",
        "print(\"f1-macro average: %f\" %knn_5_f1_macro)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiWK0_B2ptCC",
        "colab_type": "text"
      },
      "source": [
        "The f1 micro and macro averages based on the above confusion matrix are the following:\n",
        "\n",
        "- f1-micro average: 0.5\n",
        "- f1-macro average: 0.460925"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR8ZrXWlpyqM",
        "colab_type": "text"
      },
      "source": [
        "### Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnh9-HDmqVPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\nClassification Precision, Recall, F1 on the LSVT Voice Rehabilitation Data Set (20% test set) for kNN algorithm (k=5)\")\n",
        "print(classification_report(Y_test, pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4TqDm40qiQr",
        "colab_type": "text"
      },
      "source": [
        "## Cumulatively F1-scores plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e6QUorqrS1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a barplot for the F1 micro averages\n",
        "x_micro_com = x_micro.copy()\n",
        "x_micro_com.append(\"kNN algorithm (k=5)\")\n",
        "y_micro_com = y_micro.copy()\n",
        "y_micro_com.append(knn_5_f1_micro)\n",
        "\n",
        "bars = plt.bar(x_micro_com,y_micro_com, width=0.5)\n",
        "bars[5].set_color('y')\n",
        "plt.title(\"f1 micro score on different classifiers\")\n",
        "plt.ylabel(\"f1 micro score\" , color='w')\n",
        "plt.xlabel(\"Strategy\", color='w')\n",
        "plt.show()\n",
        "\n",
        "#Creating a barplot for the F1 micro averages\n",
        "x_macro_com = x_macro.copy()\n",
        "x_macro_com.append(\"kNN algorithm (k=5)\")\n",
        "y_macro_com = y_macro.copy()\n",
        "y_macro_com.append(knn_5_f1_macro)\n",
        "\n",
        "bars = plt.bar(x_macro_com,y_macro_com, width=0.5)\n",
        "bars[5].set_color('y')\n",
        "plt.title(\"f1 macro score on different classifiers\")\n",
        "plt.ylabel(\"f1 macro score\" , color='w')\n",
        "plt.xlabel(\"Strategy\", color='w')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a_4oRDSgwe6A"
      },
      "source": [
        "## Project questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Q0c7p71wesD"
      },
      "source": [
        "1. See the [Dummy classifiers](#scrollTo=Fx_cygCpuHJi) and [kNN classifier](#scrollTo=sW8JbqynzMzx) subsections.\n",
        "2. See [Cumulatively F1-scores plots](#scrollTo=B4TqDm40qiQr)\n",
        "3. First of all, its significant to remember what this dataset is about:\n",
        "\n",
        "  The LSVT Voice Rehabilitation dataset is about patients undergoing voice rehabilitation treatment in order to speak with acceptable vocal sounds (phonations). So its clear that it is more important to don't give false hopes, that the treatment lead to acceptable phonations, than to say that a patient needs more treatment even though his phonations are already acceptable.\n",
        "\n",
        "  The above statement means that our classifier has to be precise. In the sections above we noticed that the classifier that achieves the best precision is the uniform dummy classifier. Since the uniform classifier does random predicitons, most of the time ranked second and the most precise classifier was the stratified dummy classifier, which respects the distribution of examples for the classes.\n",
        "\n",
        "  Furthermore we can see in the plots above that these classifiers have good both f1 micro and f1 macro scores. This is because the examples of the test set are picked randomly, so the test set probably has the same distribution of examples for each class as the training set.\n",
        "\n",
        "  On the other hand we can see that constant 2 strategy (same as most frequent) has a good f1 micro score but a bad f1 macro score due to the imbalance of the dataset.\n",
        "\n",
        "  At last, we can see that kNN classifier performs fairly on the dataset for a baseline classification. It has good both micro and macro f1 scores, but the accuracy is just 50%. As we can see in the confusion matrix of the kNN classifier, this happens because many examples are classified as \"Unacceptable\" due to the imbalance of the classes, which means more neighbors \"voting\" the favored class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWv6PvcesyxI",
        "colab_type": "text"
      },
      "source": [
        "# Classifiers optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVuq9alvS1d7",
        "colab_type": "text"
      },
      "source": [
        "In this section we are going to implement some optimization techniques such as dataset pre-processing and hyperparameter optimization. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPyUyQ0o0T8Y",
        "colab_type": "text"
      },
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5L9H9WnbJcn",
        "colab_type": "text"
      },
      "source": [
        "We are going to try the following pre-processing methods: \\\n",
        "- Dimensionality reduction:\n",
        "  - Feature Selection (Variance threshold)\n",
        "  - Feature Extraction (Principal Components Analysis - PCA)\n",
        "- Normalization (z-score)\n",
        "- Balancing the data (Oversampling)\n",
        "\n",
        "**Note**: We won't try to balance the data with the Undersampling method since we already have a very small dataset. Undersampling it will lead to a 33.33% loss of our dataset, as we can see at the [Checking for biased data](#scrollTo=vdMHPZ6Z9Z5K) section. Also min-max scaling didn't improved the performance so it won't be used as a normalization process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF37uwB-pMJO",
        "colab_type": "text"
      },
      "source": [
        "### Feature selection - Variance Threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGIwenR3pqEi",
        "colab_type": "text"
      },
      "source": [
        "First we have to understand why dimensionality reduction is important for the k Nearest Neighbors (kNN) algorithm, regardless of the computanional cost. \\\n",
        "\\\n",
        "The distance metric calculated by the kNN algorithm is the Euclidean distance. This distance measure will become meaningless if we have a very high dimensional dataset and it is even worse if we have a small amount of examples like in our dataset. \\\n",
        "\\\n",
        "On the other hand dimensionality reduction won't help the performance of the dummy classifiers (it won't cause any damage either) since they only rely on the distribution of the labels in our dataset. \n",
        "\\\n",
        "\\\n",
        "We will apply a feature selector that removes all the low-variance features. This method is called Variance Threshold. The default value of the threshold is zero, which means that the selector will remove all the features with constant values. We will try different thresholds later and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9TSiRNJsi0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "def feat_select(train, test, thresh):\n",
        "  # Initializing a selector\n",
        "  selector = VarianceThreshold(threshold=thresh)\n",
        "  # Fiting the selector on the training set\n",
        "  train_reduced = selector.fit_transform(train)\n",
        "\n",
        "  #Applying the selector on the test set\n",
        "  test_reduced = selector.transform(test)\n",
        "\n",
        "  return train_reduced, test_reduced"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlUhztqeyYOn",
        "colab_type": "text"
      },
      "source": [
        "### Feature Extraction - PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg7UeaoRygCF",
        "colab_type": "text"
      },
      "source": [
        "We are going to apply the Principal Components Analysis as a method for feature extraction in order to achieve dimensionality reduction. The number of components is a new hyperparameter. We will experiment with different values later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOxgU2nEzp77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def princ_comp_analysis(train, test , n):\n",
        "  \n",
        "  pca = PCA(n_components=n)\n",
        "\n",
        "  # The transformation must be the same both on the training and test set.\n",
        "  # The principal components are calculated on the training set\n",
        "  train_PCA = pca.fit_transform(train)\n",
        "  test_PCA = pca.transform(test)\n",
        "\n",
        "  return train_PCA, test_PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leiAQVAMb_U6",
        "colab_type": "text"
      },
      "source": [
        "### Normalization - z-score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIoqdxo-g2Se",
        "colab_type": "text"
      },
      "source": [
        "Τhe normalization method is important for the k Nearest Neighbors (kNN) algorithm. \\\\\n",
        "\n",
        "Lets say that we have the following features in our dataset:\n",
        "- x<sub>1</sub> : with values in the range [0,1]\n",
        "- x<sub>2</sub> : with values in the range [-100000,100000]\n",
        "\n",
        "In order to find the k nearest neighbors, the kNN algorithm will calculate the distances. The most widely used distance metric for kNN is the Euclidean distance. So when taking the euclidean distance between pairs of examples, the values of the feature x<sub>1</sub> will probably become uninformative and the algorithm would rely only on the values of the x<sub>2</sub> feature. So normalization will help the kNN algorithm to take into consideration all the features. \\\\\n",
        "\n",
        "For the same reason as described above scaling the data won't help the performance of the dummy classifiers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDV0AzAVj2r_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def feat_norm(train , test):\n",
        "  #Creating a scaler object and applying fit on the training set\n",
        "  scaler = preprocessing.StandardScaler().fit(train)\n",
        "\n",
        "  #Standardizing the features of the training set\n",
        "  train_scaled = scaler.transform(train)\n",
        "\n",
        "  #Now we have to standarize the test data but with the mean and standard deviation values calculated on the training set.\n",
        "  test_scaled = scaler.transform(test)\n",
        "\n",
        "  return train_scaled, test_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBesGfBiuZb-",
        "colab_type": "text"
      },
      "source": [
        "### Balancing the data - Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fislGJHP4s_3",
        "colab_type": "text"
      },
      "source": [
        "Balancing the data is the last significant step of data pre-processing in the cross validation phase. \\\n",
        "\\\n",
        "This processing though will affect not only the performance of the kNN classifier, but the performance of the dummy classifiers too. \n",
        "\n",
        "\n",
        "**kNN algorithm** \\\n",
        "As we described above, the kNN algorithm classifies an object to the class most common among its k nearest neighbors. If though the dataset is imbalanced, it means that one of the classes has more objects than the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqh0XC4pT3vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_acc = (train_labels['Binary class 1=acceptable, 2=unacceptable']==1).sum()\n",
        "train_unacc = (train_labels['Binary class 1=acceptable, 2=unacceptable']==2).sum()\n",
        "\n",
        "print(\"There are %d acceptable examples and %d unacceptable exmaples,\" %(train_acc, train_unacc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45kklMuIT4F4",
        "colab_type": "text"
      },
      "source": [
        " In our dataset for example, we have 69 objects classified as \"Unacceptable\" and just 31 classified as \"Acceptable\". So in datasets like this, it is possible for an object to be missclassified because whilst it is closer to an object of class A (e.g. \"Acceptable\"), it has more neighbors in class B (e.g. \"Unacceptable\") due to the imbalanced number of examples. \\\n",
        "**Dummy classifiers** \\\n",
        "The performance of the dummy classifiers relies on the distribution of the classes in our dataset. If the dataset was to become balanced, the dummy strategy \"Most frequent\" has no meaning since there is 50-50 dataset. Also the performance of the stratified strategy will change as the distribution of the dataset labels changes. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F03zhVR8Lzx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "def oversampling(train,train_labels):\n",
        "  \n",
        "  # Initializing RandomOverSampler\n",
        "  ros = RandomOverSampler(random_state=0)\n",
        "  #Applying oversampling\n",
        "  train_resampled, trainTargets_resampled = ros.fit_sample(train,train_labels)\n",
        "\n",
        "  return train_resampled, trainTargets_resampled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJZKR-MY0r4v",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaMwF_XR1RpW",
        "colab_type": "text"
      },
      "source": [
        "In order to optimize our hyperparameters, we are going to implement 10-fold cross validation with gridsearch.\n",
        "\n",
        "The hyperparameters we have to tune are the following:\n",
        "- Variance threshold for feature selection\n",
        "- Number of components for PCA\n",
        "- The value of k for the kNN algorithm\n",
        "\n",
        "There are no hyperparameters to tune for the Dummy classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddXwlEG39Zjt",
        "colab_type": "text"
      },
      "source": [
        "### 10-fold cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQjv5xpJDuCQ",
        "colab_type": "text"
      },
      "source": [
        "The function below splits the training dataset into k (given as argument) folds. \\\n",
        "Each element of a fold is chosen randomly.\\\n",
        "The fuction returns two lists of arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EddN3Jo-kz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randrange\n",
        "from math import ceil\n",
        "\n",
        "# Split the training set into folds\n",
        "def kfold_split(X_train, Y_train, folds):\n",
        "  \n",
        "  X_train_split = list()\n",
        "  X_train_copy = list(X_train)\n",
        "  \n",
        "  Y_train_split = list()\n",
        "  Y_train_copy = list(Y_train)\n",
        "\n",
        "  #There may be a fold with less examples than the others\n",
        "  fold_size = ceil(len(X_train) / folds)\n",
        "\n",
        "  for i in range(folds):\n",
        "    X_fold = list()\n",
        "    Y_fold = list()\n",
        "    while (len(X_fold) < fold_size) and (len(X_train_copy)>0):\n",
        "      #Random index for the object to be removed from copied list \n",
        "      #and appended to the specific iterations' fold\n",
        "      index = randrange(len(X_train_copy))\n",
        "      X_fold.append(X_train_copy.pop(index))\n",
        "      Y_fold.append(Y_train_copy.pop(index))\n",
        "\n",
        "    X_train_split.append(np.array(X_fold))\n",
        "    Y_train_split.append(np.array(Y_fold))\n",
        "\n",
        "  return X_train_split, Y_train_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q3s_Y84RKGm",
        "colab_type": "text"
      },
      "source": [
        "### Pre-processing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BFg2cM9PwxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The function below does data pre-processing based on the given arguments\n",
        "#\n",
        "# Parameters:\n",
        "#   -variance_threshold: int/float/double, the variance threshold to use on feature selection\n",
        "#   -normalization: boolean \n",
        "#   -n_components: integer, the number of components for the Principal Components Analysis\n",
        "#   -balanced: boolean, true for oversampling\n",
        "#   -x_train: training set\n",
        "#   -y_train: training labels\n",
        "#   -x_test: test set\n",
        "#\n",
        "# Output:\n",
        "#   -x_train_resampled: the training set after applying the pre-processing techniques \n",
        "#   -y_train_resampled: the training labels after applying the pre-processing techniques \n",
        "#   -x_test_pca: the test set after applying the pre-processing techniques \n",
        "\n",
        "def pre_processing(variance_threshold, normalization, n_components, balanced, x_train, y_train, x_test):\n",
        "\n",
        "  #Feature selection\n",
        "  if variance_threshold!=None: x_train_reduced, x_test_reduced = feat_select(x_train, x_test, variance_threshold)\n",
        "  else: x_train_reduced, x_test_reduced = x_train, x_test\n",
        "\n",
        "  #Normalization\n",
        "  if normalization: x_train_normalized, x_test_normalized = feat_norm(x_train_reduced , x_test_reduced)\n",
        "  else: x_train_normalized, x_test_normalized = x_train_reduced, x_test_reduced\n",
        "\n",
        "  #Oversampling\n",
        "  if balanced: x_train_resampled, y_train_resampled = oversampling(x_train_normalized, y_train) \n",
        "  else: x_train_resampled, y_train_resampled = x_train_normalized, y_train \n",
        "  \n",
        "  #PCA\n",
        "  if n_components!=None: x_train_pca, x_test_pca = princ_comp_analysis(x_train_resampled, x_test_normalized , n_components)\n",
        "  else: x_train_pca, x_test_pca = x_train_resampled, x_test_normalized\n",
        "\n",
        "  return x_train_pca, y_train_resampled, x_test_pca"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kDXD_oXNUx7",
        "colab_type": "text"
      },
      "source": [
        "### Grid search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffFmPDT69zml",
        "colab_type": "text"
      },
      "source": [
        "In this section we implement the Grid Search Cross Validation. With this method of cross validation we basically try all different combinations of given values for hyperparameters with all different pre-processing of data techniques. Then for each combination we compute the f1-score average (type given as argument to the function) with the process of 10-fold cross validation. \n",
        "\n",
        "\\\n",
        "**Note**: Due to the small size of the dataset and the fact that it is unbalanced ([see here](#scrollTo=vdMHPZ6Z9Z5K)), we noticed that every rerun of the train_test_split function ([see here](#scrollTo=_g0gnm_oqHnN)) leads to slightly different optimal values for the hyperparamaters and different architecture model for pre-processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG8kycJVMpAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The function below removes a specific array arr from a list L of arrays\n",
        "def remove_array(L,arr):\n",
        "    ind = 0\n",
        "    size = len(L)\n",
        "    while ind != size and not np.array_equal(L[ind],arr):\n",
        "        ind += 1\n",
        "    if ind != size:\n",
        "        L.pop(ind)\n",
        "        return L\n",
        "    else:\n",
        "        raise ValueError('array not found in list.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxIECQAbBVcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "\n",
        "#A function that finds the pre-processing architecture and hyperparameters values that maximize the given \n",
        "#average metric (f1 micro or macro) using kNN algorithm.\n",
        "#\n",
        "# Parameters:\n",
        "#   -X_train: array of training set examples\n",
        "#   -Y_train: array of training set labels\n",
        "#   -var_thresh: list of values for variance threshold feature selection\n",
        "#    (input [None] if you don't want to use Variance Threshold)\n",
        "#   -n_components: lists of values for the PCA hyperparameter\n",
        "#    (input [None] if you don't want to use PCA)\n",
        "#   -n_neighbors: lists of values for the kNN hyperparameter\n",
        "#   -balanced: boolean list [True] to balance the data, [False] \n",
        "#    to not balance the data , or [True, False] to try both architectures\n",
        "#   -normalization: boolean list [True] to normalize the data, [False] \n",
        "#    to not normalize the data , or [True, False] to try both architectures\n",
        "#   -average: String value to specify which metric to use. It can be either 'micro' or 'macro'\n",
        "#\n",
        "# Output:\n",
        "#   -best_f1: the max value of the specified metric it calculated\n",
        "#   -values: a dictionary containing the specific parameters that lead to the above maximum value of the metric\n",
        "\n",
        "\n",
        "\n",
        "def gridsearch(X_train, Y_train, var_thresh, n_components, n_neighbors, balanced, normalization, average):\n",
        "  #Computing the folds for the 10-fold cross validation\n",
        "  x_folds, y_folds = kfold_split(X_train, Y_train, 10)\n",
        "\n",
        "  #Initializing the metric that we want to maximize\n",
        "  best_f1 = 0\n",
        "  #In the dictionary below we are going to keep the specific architecture\n",
        "  #and hyperparameters that lead to the max value of our metric\n",
        "  values = {}\n",
        "\n",
        "  #We use tqdm_notebook to visualize a progress bar at the output\n",
        "  for var in tqdm_notebook(var_thresh, desc='Grid search'):\n",
        "    for comp in n_components:      \n",
        "      for bal in balanced:\n",
        "        for norm in normalization:\n",
        "          for neigh in n_neighbors:\n",
        "            scores = []\n",
        "            for x_test,y_test in zip(x_folds,y_folds):\n",
        "              \n",
        "              x_train = x_folds.copy()\n",
        "              #removing the fold that we will use as test set for this iteration\n",
        "              x_train = remove_array(x_train,x_test) \n",
        "              #concatenating the rest of the folds\n",
        "              x_train = np.concatenate(x_train)\n",
        "\n",
        "              y_train = y_folds.copy()\n",
        "              #removing the fold that we will use as test set for this iteration\n",
        "              y_train = remove_array(y_train,y_test)\n",
        "              #concatenating the rest of the folds\n",
        "              y_train = np.concatenate(y_train)\n",
        "\n",
        "              #Data pre-preprocessing\n",
        "              x_train, y_train, x_test = pre_processing(var, norm, comp, bal, x_train, y_train, x_test)\n",
        "\n",
        "              #kNN classifier\n",
        "              knn = KNeighborsClassifier(n_neighbors = neigh)\n",
        "              knn.fit(x_train, y_train)\n",
        "              pred = knn.predict(x_test)\n",
        "\n",
        "              f1 = f1_score(y_test, pred, average=average)\n",
        "              scores.append(f1)\n",
        "\n",
        "            #Getting the mean value of the f1 scores calculated via 10-fold cross validation\n",
        "            f1 = np.mean(scores) \n",
        "            if (f1>best_f1):\n",
        "              best_f1 = f1\n",
        "              values['variance_threshold'] = var\n",
        "              values['n_components'] = comp\n",
        "              values['balanced'] = bal\n",
        "              values['normalized'] = norm\n",
        "              values['n_neighbors'] = neigh\n",
        "\n",
        "  return best_f1, values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhoBI6W0ANO5",
        "colab_type": "text"
      },
      "source": [
        "## Dummy classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uZZjv9tJeg_",
        "colab_type": "text"
      },
      "source": [
        "As we explained in each subsection of the [Data pre-processing](#scrollTo=pPyUyQ0o0T8Y), only the oversamping technique has an impact on the performance of the dummy classifiers since they rely only on the frequency of appearance of each label in the dataset. \n",
        "\n",
        "So lets see the performance on the oversampled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMmR09W8KHVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_dummy_oversampled, y_dummy_oversampled = oversampling(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx91l7eKYO4R",
        "colab_type": "text"
      },
      "source": [
        "Now x_dummy_oversampled and y_dummy_oversampled contain even data of each class. So lets train the dummy classifiers on the new training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcO9UV5DWW_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dc_uniform_opt = DummyClassifier(strategy=\"uniform\")\n",
        "dc_constant_1_opt = DummyClassifier(strategy=\"constant\", constant=1)\n",
        "dc_constant_2_opt = DummyClassifier(strategy=\"constant\", constant=2)\n",
        "dc_most_frequent_opt = DummyClassifier(strategy=\"most_frequent\")\n",
        "dc_stratified_opt = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "#The fit method from sklearn trains the model to the training set we provide as an argument.\n",
        "dc_uniform_opt.fit(x_dummy_oversampled, y_dummy_oversampled)\n",
        "dc_constant_1_opt.fit(x_dummy_oversampled, y_dummy_oversampled)\n",
        "dc_constant_2_opt.fit(x_dummy_oversampled, y_dummy_oversampled)\n",
        "dc_most_frequent_opt.fit(x_dummy_oversampled, y_dummy_oversampled)\n",
        "dc_stratified_opt.fit(x_dummy_oversampled, y_dummy_oversampled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU6QBY90YkqL",
        "colab_type": "text"
      },
      "source": [
        "Now that all the dummy classifiers are trained, lets make predictions on the test set and see how much the oversampling impacted on the performance of the classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-c66nBhC2ax",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-YMKf3_WYnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a dictionary with the accuracies of the dummy strategies\n",
        "dummies_accuracy_opt = {}\n",
        "dummies_accuracy_opt['uniform'] = dc_uniform_opt.score(X_test, Y_test)\n",
        "dummies_accuracy_opt['constant_1'] = dc_constant_1_opt.score(X_test, Y_test)\n",
        "dummies_accuracy_opt['constant_2'] = dc_constant_2_opt.score(X_test, Y_test)\n",
        "dummies_accuracy_opt['most frequent label'] = dc_most_frequent_opt.score(X_test, Y_test)\n",
        "dummies_accuracy_opt['stratified'] = dc_stratified_opt.score(X_test, Y_test)\n",
        "\n",
        "#Creating a barplot for the accuracies \n",
        "x_opt = [key for key in dummies_accuracy_opt.keys()]\n",
        "y_opt = [value for value in dummies_accuracy_opt.values()]\n",
        "x_len = np.arange(len(x_opt))\n",
        "bars = plt.bar(x_len-0.2,y_opt, width=0.4, label=\"optimized\")\n",
        "bars = plt.bar(x_len+0.2,y, width=0.4, label =\"baseline\")\n",
        "plt.xticks(x_len,x_opt)\n",
        "plt.title(\"Accuracy with dummy classifiers\")\n",
        "plt.ylabel(\"Accuracy\" , color='w')\n",
        "plt.xlabel(\"Strategy\", color='w')\n",
        "\n",
        "\n",
        "leg = plt.legend()\n",
        "for text in leg.get_texts():\n",
        "    plt.setp(text, color = 'black')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#Printing the sorted results\n",
        "print(\"Classification Accuracies on the LSVT Voice Rehabilitation Data Set (20% test set)\\n\")\n",
        "sorted_accuracy = [(k, dummies_accuracy_opt[k]) for k in sorted(dummies_accuracy_opt, key=dummies_accuracy_opt.get, reverse=True)]\n",
        "for k, v in sorted_accuracy:\n",
        "  print(k,v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfqDK80Hjnz9",
        "colab_type": "text"
      },
      "source": [
        "### Confusion matrices and f1 scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0TMycD96ipJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Uniform predictions\n",
        "preds_uniform_opt = dc_uniform_opt.predict(X_test)\n",
        "print(\"Uniform dummy classifier - predictions:\", end=\" \")\n",
        "print(preds_uniform_opt)\n",
        "\n",
        "#Constant 1\n",
        "preds_constant_1_opt = dc_constant_1_opt.predict(X_test)\n",
        "print(\"Constant 1 dummy classifier - predictions:\", end=\" \")\n",
        "print(preds_constant_1_opt)\n",
        "\n",
        "#Constant 2\n",
        "preds_constant_2_opt = dc_constant_2_opt.predict(X_test)\n",
        "print(\"Constant 2 dummy classifier - predictions:\", end=\" \")\n",
        "print(preds_constant_2_opt)\n",
        "\n",
        "#Most frequent predictions\n",
        "preds_most_frequent_opt= dc_most_frequent_opt.predict(X_test)\n",
        "print(\"Most frequent dummy classifier - predictions:\", end=\" \")\n",
        "print(preds_most_frequent_opt)\n",
        "\n",
        "#Stratified predictions\n",
        "preds_stratified_opt= dc_stratified_opt.predict(X_test)\n",
        "print(\"Stratified dummy classifier - predictions:\", end=\" \")\n",
        "print(preds_stratified_opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoAvnUyyXVEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculating the confusion matrices of the above strategies\n",
        "dummies_cm_opt = {}\n",
        "dummies_cm_opt['uniform'] = confusion_matrix(Y_test,preds_uniform_opt)\n",
        "dummies_cm_opt['constant_1'] = confusion_matrix(Y_test,preds_constant_1_opt)\n",
        "dummies_cm_opt['constant_2'] = confusion_matrix(Y_test,preds_constant_2_opt)\n",
        "dummies_cm_opt['most frequent label'] = confusion_matrix(Y_test,preds_most_frequent_opt)\n",
        "dummies_cm_opt['stratified'] = confusion_matrix(Y_test,preds_stratified_opt)\n",
        "\n",
        "#Calculating the f1 micro average score of the above strategies\n",
        "dummies_f1_micro_opt = {}\n",
        "dummies_f1_micro_opt['uniform'] = f1_score(Y_test, preds_uniform_opt, average=\"micro\")\n",
        "dummies_f1_micro_opt['constant_1'] = f1_score(Y_test, preds_constant_1_opt, average=\"micro\")\n",
        "dummies_f1_micro_opt['constant_2'] = f1_score(Y_test, preds_constant_2_opt, average=\"micro\")\n",
        "dummies_f1_micro_opt['most frequent label'] = f1_score(Y_test, preds_most_frequent_opt, average=\"micro\")\n",
        "dummies_f1_micro_opt['stratified'] = f1_score(Y_test, preds_stratified_opt, average=\"micro\")\n",
        "\n",
        "#Calculating the f1 macro average score of the above strategies\n",
        "dummies_f1_macro_opt = {}\n",
        "dummies_f1_macro_opt['uniform'] = f1_score(Y_test, preds_uniform_opt, average=\"macro\")\n",
        "dummies_f1_macro_opt['constant_1'] = f1_score(Y_test, preds_constant_1_opt, average=\"macro\")\n",
        "dummies_f1_macro_opt['constant_2'] = f1_score(Y_test, preds_constant_2_opt, average=\"macro\")\n",
        "dummies_f1_macro_opt['most frequent label'] = f1_score(Y_test, preds_most_frequent_opt, average=\"macro\")\n",
        "dummies_f1_macro_opt['stratified'] = f1_score(Y_test, preds_stratified_opt, average=\"macro\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-KgCs6TEYgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Confusion matrix for the \" + UNDERLINE + \"optimized uniform strategy\" + END +\":\")\n",
        "print(dummies_cm_opt['uniform'])\n",
        "print(\"f1-micro average: %f\" %dummies_f1_micro_opt['uniform'])\n",
        "print(\"f1-macro average: %f\" %dummies_f1_macro_opt['uniform'])\n",
        "\n",
        "print(\"\\nConfusion matrix for the \" + UNDERLINE + \"optimized constant 1 strategy\" + END +\":\")\n",
        "print(dummies_cm_opt['constant_1'])\n",
        "print(\"f1-micro average: %f\" %dummies_f1_micro_opt['constant_1'])\n",
        "print(\"f1-macro average: %f\" %dummies_f1_macro_opt['constant_1'])\n",
        "\n",
        "print(\"\\nConfusion matrix for the \" + UNDERLINE + \"optimized constant 2 strategy\" + END +\":\")\n",
        "print(dummies_cm_opt['constant_2'])\n",
        "print(\"f1-micro average: %f\" %dummies_f1_micro_opt['constant_2'])\n",
        "print(\"f1-macro average: %f\" %dummies_f1_macro_opt['constant_2'])\n",
        "\n",
        "print(\"\\nConfusion matrix for the \" + UNDERLINE + \"optimized most frequent strategy\" + END +\":\")\n",
        "print(dummies_cm_opt['most frequent label'])\n",
        "print(\"f1-micro average: %f\" %dummies_f1_micro_opt['most frequent label'])\n",
        "print(\"f1-macro average: %f\" %dummies_f1_macro_opt['most frequent label'])\n",
        "\n",
        "print(\"\\nConfusion matrix for the \" + UNDERLINE + \"optimized stratified strategy\" + END +\":\")\n",
        "print(dummies_cm_opt['stratified'])\n",
        "print(\"f1-micro average: %f\" %dummies_f1_micro_opt['stratified'])\n",
        "print(\"f1-macro average: %f\" %dummies_f1_macro_opt['stratified'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d1eRMwgFbXUW"
      },
      "source": [
        "So based on the output above, we have the following confusion matrices:\n",
        "\n",
        "**Uniform Strategy**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           5           |            6            |\n",
        "| Actual Unacceptables(2) |           7           |            8            |\n",
        "\n",
        "**Constant 1 Strategy**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           11           |            0            |\n",
        "| Actual Unacceptables(2) |           15           |            0            |\n",
        "\n",
        "**Constant 2 Strategy**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           0           |            11            |\n",
        "| Actual Unacceptables(2) |           0           |            15            |\n",
        "\n",
        "**Most frequent Strategy**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           11           |            0            |\n",
        "| Actual Unacceptables(2) |           15           |            0            |\n",
        "\n",
        "\n",
        "**Stratified Strategy**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           8           |            3            |\n",
        "| Actual Unacceptables(2) |           5           |            10            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1VQ-rD_Xbrqp"
      },
      "source": [
        "The f1 micro and macro averages based on the above confusion matrices are the following:\n",
        "\n",
        "- Uniform strategy\n",
        "  - f1-micro average: 0.500000\n",
        "  - f1-macro average: 0.493253\n",
        "\n",
        "- Constant 1 strategy \n",
        "  - f1-micro average: 0.423077\n",
        "  - f1-macro average: 0.297297\n",
        "\n",
        "- Constant 2 strategy \n",
        "  - f1-micro average: 0.576923\n",
        "  - f1-macro average: 0.365854\n",
        "\n",
        "- Most frequent strategy \n",
        "  - f1-micro average: 0.423077\n",
        "  - f1-macro average: 0.297297\n",
        "\n",
        "- Stratified strategy \n",
        "  - f1-micro average: 0.692308\n",
        "  - f1-macro average: 0.690476"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgSN6quADAv4",
        "colab_type": "text"
      },
      "source": [
        "### F1 scores plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mXlsQKg6Tbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a barplot for the F1 micro averages\n",
        "x_micro_opt = [key for key in dummies_f1_micro_opt.keys()]\n",
        "y_micro_opt = [value for value in dummies_f1_micro_opt.values()]\n",
        "bars = plt.bar(x_len-0.2,y_micro_opt, width=0.4,label=\"optimized\")\n",
        "bars = plt.bar(x_len+0.2,y_micro, width=0.4, label=\"baseline\")\n",
        "plt.title(\"f1 micro score with dummy classifiers\")\n",
        "plt.ylabel(\"f1 micro score\" , color='w')\n",
        "plt.xlabel(\"Strategy\", color='w')\n",
        "plt.xticks(x_len,x_micro_opt)\n",
        "\n",
        "leg = plt.legend()\n",
        "for text in leg.get_texts():\n",
        "    plt.setp(text, color = 'black')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#Creating a barplot for the F1 micro averages\n",
        "x_macro_opt = [key for key in dummies_f1_macro_opt.keys()]\n",
        "y_macro_opt = [value for value in dummies_f1_macro_opt.values()]\n",
        "bars = plt.bar(x_len-0.2,y_macro_opt, width=0.4, label=\"optimized\")\n",
        "bars = plt.bar(x_len+0.2,y_macro, width=0.4, label=\"baseline\")\n",
        "plt.title(\"f1 macro score with dummy classifiers\")\n",
        "plt.ylabel(\"f1 macro score\" , color='w')\n",
        "plt.xlabel(\"Strategy\", color='w')\n",
        "plt.xticks(x_len,x_micro_opt)\n",
        "\n",
        "leg = plt.legend()\n",
        "for text in leg.get_texts():\n",
        "    plt.setp(text, color = 'black')\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icEOcWZOFEve",
        "colab_type": "text"
      },
      "source": [
        "### Classification reports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eipu5ai5FICs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\nClassification Precision, Recall, F1 on the optimized (oversampled) dataset\")\n",
        "\n",
        "print(\"\\n\"+UNDERLINE+\"Uniform strategy\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, preds_uniform_opt))\n",
        "print(\"\\n\"+UNDERLINE+\"Constant 1 strategy\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, preds_constant_1_opt))\n",
        "print(\"\\n\"+UNDERLINE+\"Constant 2 strategy\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, preds_constant_2_opt))\n",
        "print(\"\\n\"+UNDERLINE+\"Most frequent strategy\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, preds_most_frequent_opt))\n",
        "print(\"\\n\"+UNDERLINE+\"Stratified strategy\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, preds_stratified_opt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afmG142y7kPT",
        "colab_type": "text"
      },
      "source": [
        "## k Nearest Neighbors Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp3cNNEtGRlG",
        "colab_type": "text"
      },
      "source": [
        "Now we are going to use the grid search function we implemented in order to find the optimal pre-processing architecture and hyperparameters values for the kNN algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZMNkSAB1Yse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initializing the lists of values for the hyperparameters for grid search\n",
        "var_thresh = list(range(0,19))\n",
        "n_components = list(range(2,22,2))\n",
        "n_neighbors = list(range(1,11,2))\n",
        "balanced = [True, False]\n",
        "normalization = [True, False]\n",
        "\n",
        "#The none values that we append below are used when\n",
        "#we don't want to apply that specific pre-processing method\n",
        "var_thresh.insert(0,None)\n",
        "n_components.insert(0,None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U1tQAH4VDSkC",
        "colab": {}
      },
      "source": [
        "f1_micro, val_micro = gridsearch(X_train, Y_train, var_thresh, n_components, n_neighbors, balanced, normalization, 'micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xjh6XhVKDSj9",
        "colab": {}
      },
      "source": [
        "val_micro"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7wPH1YZrDSj6",
        "colab": {}
      },
      "source": [
        "f1_micro"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_eAk5VG7DSjw",
        "colab": {}
      },
      "source": [
        "f1_macro, val_macro = gridsearch(X_train, Y_train, var_thresh, n_components, n_neighbors, balanced, normalization, 'macro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWs6x8LXR2Ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1_macro"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWEiM_ukavp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_macro"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MubClUH5ctm_",
        "colab_type": "text"
      },
      "source": [
        "###Optimal kNN models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1nmUffIfqeE",
        "colab_type": "text"
      },
      "source": [
        "As we notice in the above outputs, the models that maximizes the f1 micro score is different than the one tha maximizes the f1 macro score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAIOTQHJDZ8b",
        "colab_type": "text"
      },
      "source": [
        "In order to maximize the f1 micro score for the kNN algorithm we have to do the following:\n",
        "- Feature selection with variance threshold = 2\n",
        "- Normalization with z-score\n",
        "- kNN algorithm with number of neighbors = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU4kXexMdQBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_micro, y_train_micro, x_test_micro = pre_processing(2, True, None, False, X_train, Y_train, X_test)\n",
        "\n",
        "start_time = time.time()\n",
        "knn_micro_opt = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn_micro_opt.fit(x_train_micro, y_train_micro)\n",
        "knn_pred_micro = knn_micro_opt.predict(x_test_micro)\n",
        "knn_micro_ftime= time.time() - start_time\n",
        "\n",
        "print(\"Execution time: %f seconds\" %knn_micro_ftime)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Rp4lp1HN-x",
        "colab_type": "text"
      },
      "source": [
        "In order to maximize the f1 macro score for the kNN algorithm we have to do the following:\n",
        "- Feature selection with variance threshold = 1 \n",
        "- Normalization with z-score\n",
        "- Principal Component Analysis with number of components = 6\n",
        "- kNN algorithm with number of neighbors = 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5-50p6DfoSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_macro, y_train_macro, x_test_macro = pre_processing(1, True, 6, False, X_train, Y_train, X_test)\n",
        "\n",
        "start_time = time.time()\n",
        "knn_macro_opt = KNeighborsClassifier(n_neighbors = 7)\n",
        "knn_macro_opt.fit(x_train_macro, y_train_macro)\n",
        "knn_pred_macro = knn_macro_opt.predict(x_test_macro)\n",
        "knn_macro_ftime= time.time() - start_time\n",
        "\n",
        "print(\"Execution time: %f seconds\" %knn_macro_ftime)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq4RAptmgUPy",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CSjyu5_gj42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn_micro_acc = accuracy_score(Y_test, knn_pred_micro)\n",
        "print(\"The accuracy of the kNN optimized classifier is %f\" %knn_micro_acc)\n",
        "\n",
        "knn_macro_acc = accuracy_score(Y_test, knn_pred_macro)\n",
        "print(\"The accuracy of the kNN optimized classifier is %f\" %knn_macro_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-QuS-DXhBKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a barplot for the accuracies of the optimal models\n",
        "y_accs = [knn_micro_acc, knn_macro_acc]\n",
        "x_accs = [\"kNN optimized for f1 micro\", \"kNN optimized for f1 macro\"]\n",
        "bars = plt.bar(x_accs,y_accs, width=0.5)\n",
        "bars[1].set_color('orange')\n",
        "plt.title(\"Accuracy for the two optimal models\")\n",
        "plt.ylabel(\"Accuracy\" , color='w')\n",
        "plt.xlabel(\"Model\", color='w')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVlo3Xwan3Ln",
        "colab_type": "text"
      },
      "source": [
        "### Confusion matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tn8O9_fn6DR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Confusion matrix for the \" + UNDERLINE + \"optimized for f1 micro kNN classifier\" + END +\":\")\n",
        "print(confusion_matrix(Y_test,knn_pred_micro))\n",
        "print(\"f1-micro average: %f\" %f1_score(Y_test,knn_pred_micro, average=\"micro\"))\n",
        "print(\"f1-macro average: %f\" %f1_score(Y_test,knn_pred_micro, average=\"macro\"))\n",
        "print(\"Confusion matrix for the \" + UNDERLINE + \"optimized for f1 macro kNN classifier\" + END +\":\")\n",
        "print(confusion_matrix(Y_test,knn_pred_macro))\n",
        "print(\"f1-micro average: %f\" %f1_score(Y_test,knn_pred_macro, average=\"micro\"))\n",
        "print(\"f1-macro average: %f\" %f1_score(Y_test,knn_pred_macro, average=\"macro\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nj2yTy84ods6"
      },
      "source": [
        "So based on the output above, we have the following confusion matrices:\n",
        "\n",
        "**kNN optimized for f1 micro**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           6           |            5            |\n",
        "| Actual Unacceptables(2) |           3           |            12            |\n",
        "\n",
        "**kNN optimized for f1 macro**\n",
        "\n",
        "|                            | Predicted Acceptables(1) | Predicted Unacceptables(2) |\n",
        "|----------------------------|-----------------------|-------------------------|\n",
        "| Actual Acceptables(1)   |           7           |            4            |\n",
        "| Actual Unacceptables(2) |           3           |            12            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u-8fz9kh51X",
        "colab_type": "text"
      },
      "source": [
        "### F1 scores plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MgDfAAkirq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn_micro_f1_micro = f1_score(Y_test,knn_pred_micro,average=\"micro\")\n",
        "knn_macro_f1_micro = f1_score(Y_test,knn_pred_macro,average=\"micro\")\n",
        "\n",
        "knn_micro_f1_macro = f1_score(Y_test,knn_pred_micro,average=\"macro\")\n",
        "knn_macro_f1_macro = f1_score(Y_test,knn_pred_macro,average=\"macro\")\n",
        "\n",
        "#Creating a barplot for the f1 micro scores of the optimal models\n",
        "y_f1_micro = [knn_micro_f1_micro, knn_macro_f1_micro]\n",
        "x_f1_micro = [\"kNN optimized for f1 micro\", \"kNN optimized for f1 macro\"]\n",
        "bars = plt.bar(x_f1_micro,y_f1_micro, width=0.5)\n",
        "bars[1].set_color('orange')\n",
        "plt.title(\"F1 micro scores for the two optimal models\")\n",
        "plt.ylabel(\"F1 micro score\" , color='w')\n",
        "plt.xlabel(\"Model\", color='w')\n",
        "plt.show()\n",
        "\n",
        "#Creating a barplot for the f1 macro scores of the optimal models\n",
        "y_f1_macro = [knn_micro_f1_macro, knn_macro_f1_macro]\n",
        "x_f1_macro = [\"kNN optimized for f1 micro\", \"kNN optimized for f1 macro\"]\n",
        "bars = plt.bar(x_f1_macro,y_f1_macro, width=0.5)\n",
        "bars[1].set_color('orange')\n",
        "plt.title(\"F1 macro scores for the two optimal models\")\n",
        "plt.ylabel(\"F1 macro score\" , color='w')\n",
        "plt.xlabel(\"Model\", color='w')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqYmCr4AkRbR",
        "colab_type": "text"
      },
      "source": [
        "### Classification reports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGV41lK2lXw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\nClassification Precision, Recall, F1 on the optimized dataset for kNN\")\n",
        "\n",
        "print(\"\\n\"+UNDERLINE+\"kNN optimized for f1 micro\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, knn_pred_micro))\n",
        "print(\"\\n\"+UNDERLINE+\"kNN optimized for f1 macro\"+END+\"\\n\")\n",
        "print(classification_report(Y_test, knn_pred_macro))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3kdqhXQluhB",
        "colab_type": "text"
      },
      "source": [
        "## Cumulatively F1-scores plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCqpMPkgl62f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a barplot for the F1 micro averages\n",
        "x_micro_opt_com = x_micro_opt.copy()\n",
        "x_micro_opt_com.append(\"kNN algorithm optimized for f1 micro\")\n",
        "x_micro_opt_com.append(\"kNN algorithm optimized for f1 macro\")\n",
        "y_micro_opt_com = y_micro.copy()\n",
        "y_micro_opt_com.append(knn_micro_f1_micro)\n",
        "y_micro_opt_com.append(knn_macro_f1_micro)\n",
        "\n",
        "bars = plt.bar(x_micro_opt_com,y_micro_opt_com, width=0.5)\n",
        "bars[5].set_color('y')\n",
        "bars[6].set_color('orange')\n",
        "plt.title(\"f1 micro score on different classifiers\")\n",
        "plt.ylabel(\"f1 micro score\" , color='w')\n",
        "plt.xlabel(\"Model\", color='w')\n",
        "plt.show()\n",
        "\n",
        "#Creating a barplot for the F1 micro averages\n",
        "x_macro_opt_com = x_macro_opt.copy()\n",
        "x_macro_opt_com.append(\"kNN algorithm optimized for f1 micro\")\n",
        "x_macro_opt_com.append(\"kNN algorithm optimized for f1 macro\")\n",
        "y_macro_opt_com = y_macro.copy()\n",
        "y_macro_opt_com.append(knn_micro_f1_macro)\n",
        "y_macro_opt_com.append(knn_macro_f1_macro)\n",
        "\n",
        "bars = plt.bar(x_macro_opt_com,y_macro_opt_com, width=0.5)\n",
        "bars[5].set_color('y')\n",
        "bars[6].set_color('orange')\n",
        "plt.title(\"f1 macro score on different classifiers\")\n",
        "plt.ylabel(\"f1 macro score\" , color='w')\n",
        "plt.xlabel(\"Model\", color='w')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1EyAieuEwegG"
      },
      "source": [
        "## Project questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K1ukiGHeweSf"
      },
      "source": [
        "1. See the subsections of [Dummy classifiers](#scrollTo=QhoBI6W0ANO5) and [k Nearest Neighbors](#scrollTo=afmG142y7kPT)\n",
        "2. We have the following table based on the output in the section [Optimal kNN models](#scrollTo=MubClUH5ctm_):\n",
        "\n",
        "| Model                      | Execution time |\n",
        "|----------------------------|----------------|\n",
        "| kNN optimized for f1 micro |       0.005419  seconds       |\n",
        "| kNN optimized for f1 macro |        0.004044   seconds     |\n",
        "\n",
        "3. See [Cumulatively F1-scores plots](#scrollTo=s3kdqhXQluhB)  \n",
        "4. We have the following table:\n",
        "\n",
        "| Model\\Metric                           | Baseline accuracy | Optimized accuracy | Baseline f1 micro score | Optimized f1 micro score | Baseline f1 macro score | Optimized f1 macro score |\n",
        "|----------------------------------------|-------------------|--------------------|-------------------------|--------------------------|-------------------------|--------------------------|\n",
        "| Uniform dummy classifier               |      0.538461     |         0.5        |         0.538462        |            0.5           |         0.535714        |         0.493253         |\n",
        "| Constant 1 dummy classifier            |      0.423076     |      0.423076      |         0.423077        |         0.423077         |         0.297297        |         0.297297         |\n",
        "| Constant 2 dummy classifier            |      0.576923     |      0.576923      |         0.576923        |         0.576923         |         0.365854        |         0.385854         |\n",
        "| Most frequent dummy classifier         |      0.576923     |      0.423076      |         0.576923        |         0.423077         |         0.685854        |         0.297297         |\n",
        "| Stratified dummy classifier            |      0.461538     |      0.384615      |         0.538462        |         0.692308         |         0.512500        |         0.690476         |\n",
        "| Baseline kNN                           |        0.5        |          -         |           0.5           |             -            |         0.460925        |             -            |\n",
        "| kNN classifier optimized for f1 micro  |         -         |      0.692308      |            -            |         0.692308         |            -            |           0.675          |\n",
        "| kNN classifier optimized for f1 macro  |         -         |      0.730769      |            -            |         0.730769         |            -            |         0.720430         |\n",
        "\n",
        "\n",
        "5. As we can see in the table above, the most improved performance by the optimization is that of the kNN classifiers. Both kNN optimized for micro f1 score and kNN optimized for macro f1 score perform very well (in comparison with the baseline classification) on our test set. \n",
        "\n",
        "  Its interesting to notice that while the first kNN classifier was optimized to maximize the f1 micro score, the second classifier (optimized for f1 macro score) scores a higher f1 micro score on the test set. This happens because the macro average computes the metric independently for each class and then takes the average, so it treats all the classes equally, whereas the micro average will aggregate the contributions of all classes to compute the average metric. We also know that our trainning set is imbalanced. That said the micro average won't treat the lower class (\"Acceptables\") equally and this is why the kNN classifier optimized for f1 macro performs best.\n",
        "\n",
        "  In addition, as we can see in the [Cumulatively F1-scores plots](#scrollTo=s3kdqhXQluhB), the classifier that perfroms best is the kNN optimized for f1 macro. This is because this kNN classifier respects the distribution of the classes and also due to the optimal pre-processing of the data, its able to separate better the objects of each class.\n",
        "\n",
        "  Furthermore, another observation that we can make based on the table above and the plots is that balancing the data via the process of oversampling, doesn't help the dummy classifiers. Since the classes are balanced, the most frequent strategy is the \"Constant 1\", probably in alphabetical order. But the test set distribution is not balanced. So it will also favor the \"Unacceptable\" class. This means that the most frequent strategy will perform worse after balancing the data. The same thing happens to the stratified strategy. It also respects the distribution of the classes in the training set. Now that the training set is balanced, its predictions will also be even in reference to the classes. So as we expect the accuracy of this classifier drops in the imbalanced test set. It's interesting though to notice that the f1 scores, both micro and macro average, rise up. The values we get for these metrics are comparable to the ones of the kNN classifiers.\n",
        "\n",
        "  As for the precision and recall, we can also see that the classifiers that perform better at these metrics, are the kNN classifiers. For the same reason as above, the stratified dummy classifiers has an equal (or close enough) perfromance at this metrics.\n",
        "\n",
        "  At last, as we can see above the execution time we need to fit and make predictions with the kNN classifiers is quite low. For the first classifier (kNN optimized for micro average) we need just 0.005419 seconds and for the second classifier (kNN optimized for macro average) we need 0.004044 seconds. These low execution times are mainly because of the small training set they try to fit, but also because of the nature of the kNN algorithm itself.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}